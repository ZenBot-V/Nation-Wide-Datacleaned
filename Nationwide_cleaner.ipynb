{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the header mapping from Chinese to English\n",
        "header_mapping = {\n",
        "    '车架号': 'VIN',\n",
        "    '姓名': 'Name',\n",
        "    '身份证': 'ID_Number',\n",
        "    '性别': 'Gender',\n",
        "    '手机': 'Mobile_Phone',\n",
        "    '邮箱': 'Email',\n",
        "    '省': 'Province',\n",
        "    '城市': 'City',\n",
        "    '地址': 'Address',\n",
        "    '邮编': 'Postal_Code',\n",
        "    '生日': 'Date_of_Birth',\n",
        "    '行业': 'Industry',\n",
        "    '月薪': 'Monthly_Salary',\n",
        "    '婚姻': 'Marital_Status',\n",
        "    '教育': 'Education',\n",
        "    'BRAND': 'Brand',\n",
        "    '车系': 'Vehicle_Series',\n",
        "    '车型': 'Vehicle_Model',\n",
        "    '配置': 'Configuration',\n",
        "    '颜色': 'Color',\n",
        "    '发动机号': 'Engine_Number'\n",
        "}\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = '/content/760k-Car-Owners-Nationwide-China-csv-2020.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Rename the columns using the header mapping\n",
        "df.rename(columns=header_mapping, inplace=True)\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file\n",
        "output_file_path = '/content/nationwide_trans.csv'\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "# Display the first few rows to confirm changes\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "0Vo21fEWlRcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the previously translated CSV file with specified data types\n",
        "file_path = '/content/nationwide_trans.csv'\n",
        "\n",
        "# Specifying dtype to avoid mixed types warnings\n",
        "dtype_mapping = {\n",
        "    'VIN': str,\n",
        "    'Name': str,\n",
        "    'ID_Number': str,\n",
        "    'Gender': str,\n",
        "    'Mobile_Phone': str,\n",
        "    'Email': str,\n",
        "    'Province': str,\n",
        "    'City': str,\n",
        "    'Address': str,\n",
        "    'Postal_Code': str,\n",
        "    'Monthly_Salary': str,\n",
        "    'Marital_Status': str,\n",
        "    'Education': str,\n",
        "    'Brand': str,\n",
        "    'Vehicle_Series': str,\n",
        "    'Vehicle_Model': str,\n",
        "    'Configuration': str,\n",
        "    'Color': str,\n",
        "    'Engine_Number': str\n",
        "}\n",
        "\n",
        "# Load the DataFrame with the specified dtype\n",
        "df = pd.read_csv(file_path, dtype=dtype_mapping)\n",
        "\n",
        "# Display the original DataFrame to check the structure\n",
        "print(\"Original DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "# Convert potential float values to string before applying .join\n",
        "for col in ['Address', 'City', 'Province', 'Postal_Code']:\n",
        "    df[col] = df[col].astype(str)  # Convert any numeric values to strings\n",
        "\n",
        "# Combine 'Address', 'City', 'Province', 'Postal_Code' into one column 'Full_Address'\n",
        "df['Full_Address'] = df[['Address', 'City', 'Province', 'Postal_Code']].agg(', '.join, axis=1)\n",
        "\n",
        "# List of columns to remove\n",
        "columns_to_remove = [\n",
        "    'ID_Number',\n",
        "    'Gender',\n",
        "    'Address',\n",
        "    'City',\n",
        "    'Province',\n",
        "    'Postal_Code',\n",
        "    'Date_of_Birth',  # Ensure this matches the translated name\n",
        "    'Industry',       # Ensure this matches the translated name\n",
        "    'Monthly_Salary',\n",
        "    'Marital_Status',\n",
        "    'Education',\n",
        "    'Configuration',\n",
        "    'Color',\n",
        "    'unnamed_21'      # Trying to remove unnamed_21\n",
        "]\n",
        "\n",
        "# Check for 'Unnamed: 21' or similar variations and add them to the list\n",
        "columns_to_remove += [col for col in df.columns if 'Unnamed' in col]\n",
        "\n",
        "# Drop only columns that exist in the DataFrame\n",
        "df_cleaned = df.drop(columns=[col for col in columns_to_remove if col in df.columns])\n",
        "\n",
        "# Remove duplicate rows\n",
        "df_cleaned = df_cleaned.drop_duplicates()\n",
        "\n",
        "# Display the cleaned DataFrame to verify removal and combination\n",
        "print(\"\\nCleaned DataFrame with combined address and duplicates removed:\")\n",
        "print(df_cleaned[['Full_Address']].head())\n",
        "\n",
        "# Save the cleaned DataFrame to a new CSV file as nationwide_pan1\n",
        "output_file_path = '/content/nationwide_pan1.csv'\n",
        "df_cleaned.to_csv(output_file_path, index=False)\n",
        "\n",
        "# Verify the columns in the cleaned DataFrame\n",
        "print(\"\\nColumns in cleaned DataFrame:\")\n",
        "print(df_cleaned.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c7oyhQXnysH",
        "outputId": "2fe7109d-abca-476c-8482-5a168af8376a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "                 VIN Name           ID_Number Gender Mobile_Phone  \\\n",
            "0  LSGLP84X2DF248935  马宏刚  432326197709250132      男  13873752623   \n",
            "1  LSGSA52M7ED215740   杨威  42060619860917201X      男  15605965992   \n",
            "2  LSGPB54U4ED067501   袁凯  342901199203026435      男  18301866904   \n",
            "3  LSGPC54U4EF169771  陈博天  420625198711290070      男  18838133331   \n",
            "4  LSGGF53W3EH096133   徐彬  110106197711301514      男  13801274963   \n",
            "\n",
            "                 Email Province City               Address Postal_Code  ...  \\\n",
            "0     534260098@qq.com      湖南省  益阳市       湖南省安化县东坪镇杨溪路31号    413000.0  ...   \n",
            "1  15605965992@163.com      湖北省  武汉市         武汉市洪山区鲁磨路485号    430000.0  ...   \n",
            "2  tongtu96818@126.com      上海市  上海市        上海市闵行区中春路1500号    201109.0  ...   \n",
            "3  18838133331@139.com      河南省  郑州市  河南省郑州市商鼎路107附道向东200米    450000.0  ...   \n",
            "4  13801274963@126.com      北京市  北京市      北京市丰台区卢沟桥五里店336号    100070.0  ...   \n",
            "\n",
            "  Monthly_Salary Marital_Status Education Brand Vehicle_Series  \\\n",
            "0       50000元以上             已婚        大专   雪佛兰        科帕奇 CKD   \n",
            "1     6000－9999元             已婚        大专   雪佛兰          新赛欧三厢   \n",
            "2     6000－9999元             未婚        大专    别克          英朗 GT   \n",
            "3     3000－5999元             未婚        大专   雪佛兰          科鲁兹三厢   \n",
            "4   20000－24999元             已婚        大本    别克           全新君越   \n",
            "\n",
            "       Vehicle_Model                             Configuration  \\\n",
            "0  科帕奇 C140  CKD 2.4  Captiva 2.4 LT AWD(Comfort)(5seat) 13含附件   \n",
            "1           新赛欧三厢豪华型                       新赛欧三厢1.4MT幸福III版 14   \n",
            "2           英朗 GT GL                        英朗 GT 1.6L手动进取型 14   \n",
            "3           科鲁兹三厢 SE                        科鲁兹三厢 1.6 SE MT 14   \n",
            "4            全新君越 GL           全新君越 2.4L SIDI 精英舒适型(加热)(棕红) 14   \n",
            "\n",
            "                            Color   Engine_Number Unnamed: 21  \n",
            "0                     晶石黑;耀石黑;旷夜黑  LE9*140800786*              \n",
            "1  珍珠白;幻白;象牙白;茉莉白;雪域白;闪电白;流光白;皓沙白  LCU*D83120897*              \n",
            "2                             卡其金  LDE*140021440*              \n",
            "3  珍珠白;幻白;象牙白;茉莉白;雪域白;闪电白;流光白;皓沙白  LDE*141090863*              \n",
            "4               墨玉黑;元黑;炫黑;钢琴黑;爵士黑  LAF*140370116*              \n",
            "\n",
            "[5 rows x 22 columns]\n",
            "\n",
            "Cleaned DataFrame with combined address and duplicates removed:\n",
            "                               Full_Address\n",
            "0       湖南省安化县东坪镇杨溪路31号, 益阳市, 湖南省, 413000.0\n",
            "1         武汉市洪山区鲁磨路485号, 武汉市, 湖北省, 430000.0\n",
            "2        上海市闵行区中春路1500号, 上海市, 上海市, 201109.0\n",
            "3  河南省郑州市商鼎路107附道向东200米, 郑州市, 河南省, 450000.0\n",
            "4      北京市丰台区卢沟桥五里店336号, 北京市, 北京市, 100070.0\n",
            "\n",
            "Columns in cleaned DataFrame:\n",
            "Index(['VIN', 'Name', 'Mobile_Phone', 'Email', 'Brand', 'Vehicle_Series',\n",
            "       'Vehicle_Model', 'Engine_Number', 'Full_Address'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the cleaned CSV file\n",
        "output_file_path = '/content/nationwide_pan1.csv'\n",
        "df_validated = pd.read_csv(output_file_path)\n",
        "\n",
        "# Validation 1: Check for any 'Unnamed' columns (i.e., columns that shouldn't be there)\n",
        "unnamed_columns = [col for col in df_validated.columns if 'Unnamed' in col]\n",
        "if unnamed_columns:\n",
        "    print(f\"Unexpected columns found: {unnamed_columns}\")\n",
        "else:\n",
        "    print(\"No 'Unnamed' columns found. Validation passed for column names.\")\n",
        "\n",
        "# Validation 2: Check if 'Full_Address' exists and if it contains the combined address\n",
        "if 'Full_Address' in df_validated.columns:\n",
        "    print(\"'Full_Address' column exists. Validation passed for address combination.\")\n",
        "    # Sample a few rows to inspect the values\n",
        "    print(df_validated[['Full_Address']].head())\n",
        "else:\n",
        "    print(\"'Full_Address' column is missing. Address combination validation failed.\")\n",
        "\n",
        "# Validation 3: Ensure that there are no duplicates\n",
        "initial_row_count = len(df_validated)\n",
        "df_no_duplicates = df_validated.drop_duplicates()\n",
        "final_row_count = len(df_no_duplicates)\n",
        "\n",
        "if initial_row_count == final_row_count:\n",
        "    print(f\"No duplicates found. Row count: {initial_row_count}\")\n",
        "else:\n",
        "    print(f\"Duplicates were found and removed. Reduced from {initial_row_count} to {final_row_count}\")\n",
        "\n",
        "# Validation 4: Check if the correct columns were retained\n",
        "expected_columns = ['VIN', 'Name', 'Mobile_Phone', 'Email', 'Brand', 'Vehicle_Series',\n",
        "                    'Vehicle_Model', 'Engine_Number', 'Full_Address']\n",
        "\n",
        "# Columns that should be present in the final cleaned DataFrame\n",
        "missing_columns = [col for col in expected_columns if col not in df_validated.columns]\n",
        "extra_columns = [col for col in df_validated.columns if col not in expected_columns]\n",
        "\n",
        "if missing_columns:\n",
        "    print(f\"Missing expected columns: {missing_columns}\")\n",
        "else:\n",
        "    print(\"All expected columns are present.\")\n",
        "\n",
        "if extra_columns:\n",
        "    print(f\"Unexpected extra columns found: {extra_columns}\")\n",
        "else:\n",
        "    print(\"No unexpected extra columns found.\")\n",
        "\n",
        "# Validation Summary\n",
        "print(\"\\nValidation Summary:\")\n",
        "print(f\"Total rows: {initial_row_count}\")\n",
        "print(f\"Total columns: {len(df_validated.columns)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SE35RM5koG8",
        "outputId": "2dee6992-c056-4499-eeb8-caf54d1ac128"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-f575b0d3592e>:5: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_validated = pd.read_csv(output_file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No 'Unnamed' columns found. Validation passed for column names.\n",
            "'Full_Address' column exists. Validation passed for address combination.\n",
            "                               Full_Address\n",
            "0       湖南省安化县东坪镇杨溪路31号, 益阳市, 湖南省, 413000.0\n",
            "1         武汉市洪山区鲁磨路485号, 武汉市, 湖北省, 430000.0\n",
            "2        上海市闵行区中春路1500号, 上海市, 上海市, 201109.0\n",
            "3  河南省郑州市商鼎路107附道向东200米, 郑州市, 河南省, 450000.0\n",
            "4      北京市丰台区卢沟桥五里店336号, 北京市, 北京市, 100070.0\n",
            "No duplicates found. Row count: 763386\n",
            "All expected columns are present.\n",
            "No unexpected extra columns found.\n",
            "\n",
            "Validation Summary:\n",
            "Total rows: 763386\n",
            "Total columns: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "66LUVM7Rm8b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the path of the original CSV file and the output directory\n",
        "file_path = '/content/nationwide_pan1.csv'\n",
        "output_dir = '/content/new_cleaned_chunks/'\n",
        "\n",
        "# Create the output directory if it does not exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Define the number of chunks\n",
        "num_chunks = 4\n",
        "\n",
        "# Read the original CSV file in chunks\n",
        "chunksize = sum(1 for _ in open(file_path)) // num_chunks\n",
        "\n",
        "# Chunk the CSV and save each chunk as a separate file\n",
        "chunk_number = 0\n",
        "for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
        "    output_file_path = os.path.join(output_dir, f'nationwide_pan1_chunk_{chunk_number + 1}.csv')\n",
        "    chunk.to_csv(output_file_path, index=False)\n",
        "    print(f'Chunk {chunk_number + 1} saved to {output_file_path}')\n",
        "    chunk_number += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBoSzQ6orXL6",
        "outputId": "0103c9df-53b8-48e1-9772-d0cfa59bde38"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1 saved to /content/new_cleaned_chunks/nationwide_pan1_chunk_1.csv\n",
            "Chunk 2 saved to /content/new_cleaned_chunks/nationwide_pan1_chunk_2.csv\n",
            "Chunk 3 saved to /content/new_cleaned_chunks/nationwide_pan1_chunk_3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-749fd8a1f9d8>:19: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  for chunk in pd.read_csv(file_path, chunksize=chunksize):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 4 saved to /content/new_cleaned_chunks/nationwide_pan1_chunk_4.csv\n",
            "Chunk 5 saved to /content/new_cleaned_chunks/nationwide_pan1_chunk_5.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Define the directory containing the chunks and the output file path\n",
        "chunks_dir = '/content/new_cleaned_chunks/'\n",
        "output_file = '/content/nationwide_cleaned_final.csv'\n",
        "\n",
        "# List all chunk files in the directory\n",
        "chunk_files = sorted(glob.glob(os.path.join(chunks_dir, 'nationwide_pan1_chunk_*.csv')))\n",
        "\n",
        "# Initialize an empty list to hold dataframes\n",
        "dataframes = []\n",
        "\n",
        "# Read each chunk and append it to the list\n",
        "for chunk_file in chunk_files:\n",
        "    df_chunk = pd.read_csv(chunk_file)\n",
        "    dataframes.append(df_chunk)\n",
        "\n",
        "# Concatenate all the dataframes into one\n",
        "final_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Save the final merged DataFrame to a new CSV file\n",
        "final_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f'Merged file saved as {output_file}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhaK_W4EcY9f",
        "outputId": "1d482834-135d-4301-dfe6-0cc9b272b278"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-48ca621e3dc5>:17: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_chunk = pd.read_csv(chunk_file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged file saved as /content/nationwide_cleaned_final.csv\n"
          ]
        }
      ]
    }
  ]
}